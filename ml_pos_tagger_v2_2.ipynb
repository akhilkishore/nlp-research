{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_pos_tagger_v2_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5tppvm2SSz0",
        "colab_type": "code",
        "outputId": "8a5f1542-b425-416a-9670-6b7e5f884ced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRIs-MhESeLU",
        "colab_type": "code",
        "outputId": "660efd1d-0168-4039-dc9a-537a571f4de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "f = open(\"/content/drive/My Drive/Malayalam_NLP/Data/pos_tagged_data/Malayalam_Tagged_Data.txt\",\"r\")\n",
        "data = f.read()\n",
        "print(len(data))\n",
        "data = data.split(\".        \\RD_PUNC\")\n",
        "all_sent = []\n",
        "for x in data:\n",
        "    x = x.split(\"\\n\")\n",
        "    v = []\n",
        "    for y in x:\n",
        "        if y != \"\":\n",
        "            y = y.replace(\"\\\\\",\"\")\n",
        "            y = y.split(\"        \")\n",
        "            v.append( (y[0],y[1]) )\n",
        "    v.append(('.','RD_PUNC'))\n",
        "    all_sent.append(v)\n",
        "del data\n",
        "sentences = all_sent\n",
        "del all_sent\n",
        "print(len(sentences))\n",
        "\n",
        "sentences = sentences[:5000]\n",
        "print(len(sentences))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7041405\n",
            "29077\n",
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkaRyDETMOFt",
        "colab_type": "code",
        "outputId": "cc4ce7ca-517d-4062-d9a3-468f2dead559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import random\n",
        "sentences = random.sample(sentences, len(sentences)) \n",
        "print(len(sentences))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lw5wWsGSmSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_test_cutoff = int(.80 * len(sentences)) \n",
        "training_sentences = sentences[:train_test_cutoff]\n",
        "testing_sentences = sentences[train_test_cutoff:]\n",
        "train_val_cutoff = int(.25 * len(training_sentences))\n",
        "validation_sentences = training_sentences[:train_val_cutoff]\n",
        "training_sentences = training_sentences[train_val_cutoff:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgtbVFPFMNGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0vxFAFsSpzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_basic_features(sentence_terms, index):\n",
        "    \"\"\" Compute some very basic word features.        :param sentence_terms: [w1, w2, ...] \n",
        "        :type sentence_terms: list\n",
        "        :param index: the index of the word \n",
        "        :type index: int\n",
        "        :return: dict containing features\n",
        "        :rtype: dict\n",
        "    \"\"\"\n",
        "    term = sentence_terms[index]\n",
        "    return {\n",
        "        'nb_terms': len(sentence_terms),\n",
        "        'term': term,\n",
        "        'is_first': index == 0,\n",
        "        'is_last': index == len(sentence_terms) - 1,\n",
        "        'prefix-1': term[0],\n",
        "        'prefix-2': term[:2],\n",
        "        'prefix-3': term[:3],\n",
        "        'suffix-1': term[-1],\n",
        "        'suffix-2': term[-2:],\n",
        "        'suffix-3': term[-3:],\n",
        "        'prev_word': '' if index == 0 else sentence_terms[index - 1],\n",
        "        'next_word': '' if index == len(sentence_terms) - 1 else sentence_terms[index + 1],\n",
        "        'prev_word2': '' if index == 0 else sentence_terms[index - 2],\n",
        "        'next_word2': '' if index > len(sentence_terms)-3 else sentence_terms[index + 2]\n",
        "\n",
        "         \n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynKljPlESvHh",
        "colab_type": "code",
        "outputId": "3b31ba33-d684-4a6f-bd21-9ffe4be3987e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(add_basic_features(sentences[0],1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'nb_terms': 3, 'term': ('ശരിയാണ്', 'V_VAUX'), 'is_first': False, 'is_last': False, 'prefix-1': 'ശരിയാണ്', 'prefix-2': ('ശരിയാണ്', 'V_VAUX'), 'prefix-3': ('ശരിയാണ്', 'V_VAUX'), 'suffix-1': 'V_VAUX', 'suffix-2': ('ശരിയാണ്', 'V_VAUX'), 'suffix-3': ('ശരിയാണ്', 'V_VAUX'), 'prev_word': ('ചക്ര', 'N_NN'), 'next_word': ('.', 'RD_PUNC'), 'prev_word2': ('.', 'RD_PUNC'), 'next_word2': ''}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3Slw136SxFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def untag(tagged_sentence):\n",
        "    \"\"\" \n",
        "    Remove the tag for each tagged term.:param tagged_sentence: a POS tagged sentence\n",
        "    :type tagged_sentence: list\n",
        "    :return: a list of tags\n",
        "    :rtype: list of strings\n",
        "    \"\"\"\n",
        "    return [w for w, _ in tagged_sentence]\n",
        "def transform_to_dataset(tagged_sentences):\n",
        "    \"\"\"\n",
        "    Split tagged sentences to X and y datasets and append some basic features.:param tagged_sentences: a list of POS tagged sentences\n",
        "    :param tagged_sentences: list of list of tuples (term_i, tag_i)\n",
        "    :return: \n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for pos_tags in tagged_sentences:\n",
        "        for index, (term, class_) in enumerate(pos_tags):\n",
        "            # Add basic NLP features for each sentence term\n",
        "            X.append(add_basic_features(untag(\n",
        "              pos_tags), index))\n",
        "            y.append(class_)\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0RWsvUoSzJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = transform_to_dataset(training_sentences)\n",
        "X_test, y_test = transform_to_dataset(testing_sentences)\n",
        "X_val, y_val = transform_to_dataset(validation_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrFE46WoS2Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del training_sentences\n",
        "del testing_sentences\n",
        "del validation_sentences\n",
        "del sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-ycHbOTS3ut",
        "colab_type": "code",
        "outputId": "e4e5dde0-aaea-45dc-bba8-10be0adcc7f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(X_train[1])\n",
        "print(y_train[1])\n",
        "print(y_test[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'nb_terms': 14, 'term': 'ജനലുകളിലും', 'is_first': False, 'is_last': False, 'prefix-1': 'ജ', 'prefix-2': 'ജന', 'prefix-3': 'ജനല', 'suffix-1': 'ം', 'suffix-2': 'ും', 'suffix-3': 'ലും', 'prev_word': 'അതിനാല്\\u200d', 'next_word': 'വാതിലു', 'prev_word2': '.', 'next_word2': 'കളിലും'}\n",
            "N_NN\n",
            "V_VM_VNF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa2iH7QXS5p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer# Fit our DictVectorizer with our set of features\n",
        "dict_vectorizer = DictVectorizer(sparse=False)\n",
        "dict_vectorizer.fit(X_train + X_test + X_val)# Convert dict features to vectors\n",
        "X_train = dict_vectorizer.transform(X_train)\n",
        "X_test = dict_vectorizer.transform(X_test)\n",
        "X_val = dict_vectorizer.transform(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIbT_Pj2S9Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder# Fit LabelEncoder with our list of classes\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train + y_test + y_val)# Encode class values as integers\n",
        "y3 = y_train\n",
        "y_train = label_encoder.transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "y_val = label_encoder.transform(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHpqBxieH78L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXSzlt_8TCd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Convert integers to dummy variables (one hot encoded)\n",
        "\n",
        "from keras.utils import np_utils\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "y_val = np_utils.to_categorical(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VChTg5MIK8Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_test[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5t9Liw8TEOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "def build_model(input_dim, hidden_neurons, output_dim):\n",
        "    \"\"\"\n",
        "    Construct, compile and return a Keras model which will be used to fit/predict\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(hidden_neurons, input_dim=input_dim),\n",
        "        Activation('relu'),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(hidden_neurons),\n",
        "        Activation('relu'),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(hidden_neurons),\n",
        "        Activation('relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(output_dim, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYiBP8k5UFTm",
        "colab_type": "code",
        "outputId": "73945357-c0ff-42c5-ce9a-85a58fd4694b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(X_train.shape[1],y_train.shape[1])\n",
        "print(X_test.shape[1],y_test.shape[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59124 33\n",
            "59124 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRlyw_HjTGgi",
        "colab_type": "code",
        "outputId": "880de519-06ac-4b67-cc7c-3ca369e69aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "source": [
        "model = build_model(X_train.shape[1],512,y_train.shape[1])\n",
        "model = model.fit(X_train, y_train, epochs=5, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/5\n",
            "12913/12913 [==============================] - 109s 8ms/step - loss: 1.1936 - acc: 0.6620\n",
            "Epoch 2/5\n",
            "12913/12913 [==============================] - 106s 8ms/step - loss: 0.3349 - acc: 0.9051\n",
            "Epoch 3/5\n",
            "12913/12913 [==============================] - 106s 8ms/step - loss: 0.1012 - acc: 0.9725\n",
            "Epoch 4/5\n",
            "12913/12913 [==============================] - 105s 8ms/step - loss: 0.0522 - acc: 0.9858\n",
            "Epoch 5/5\n",
            "12913/12913 [==============================] - 105s 8ms/step - loss: 0.0337 - acc: 0.9916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q54GDLPZTKIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.model.save('model_v2_2.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "del model  # deletes the existing model\n",
        "\n",
        "# returns a compiled model\n",
        "\n",
        "# identical to the previous one\n",
        "model = load_model('model_v2_2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDN2xYqrTI6C",
        "colab_type": "code",
        "outputId": "635d130e-3cbe-4efa-f374-7bf39a4e9fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "loss, accuracy = model.model.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 160/4116 [>.............................] - ETA: 4s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4116/4116 [==============================] - 4s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSo-OuY-T_hP",
        "colab_type": "code",
        "outputId": "d286a867-ec5c-4a10-a2ec-1eaac94b4c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(loss, accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8881109667357249 0.8170553936439306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3Y-4M0mIauX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}