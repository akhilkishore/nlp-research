{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_pos_LSTM_word_level",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwQXSzkodJtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75ilch-_dSAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgwoW8EldSYV",
        "colab_type": "code",
        "outputId": "1f300de3-b4b1-4732-d716-376da87e1a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "f = open(\"/content/drive/My Drive/Malayalam_NLP/Data/pos_tagged_data/Malayalam_Tagged_Data.txt\",\"r\")\n",
        "data = f.read()\n",
        "print(len(data))\n",
        "data = data.split(\".        \\RD_PUNC\")\n",
        "all_sent = []\n",
        "for x in data:\n",
        "    x = x.split(\"\\n\")\n",
        "    v = []\n",
        "    for y in x:\n",
        "        if y != \"\":\n",
        "            y = y.replace(\"\\\\\",\"\")\n",
        "            y = y.split(\"        \")\n",
        "            v.append( (y[0],y[1]) )\n",
        "    v.append(('.','RD_PUNC'))\n",
        "    all_sent.append(v)\n",
        "del data\n",
        "sentences = all_sent\n",
        "del all_sent\n",
        "print(len(sentences))\n",
        "\n",
        "sentences = sentences[:5000]\n",
        "print(len(sentences))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7041405\n",
            "29077\n",
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spFNijStdbBf",
        "colab_type": "code",
        "outputId": "b2146ea8-e291-41b0-e85b-196d31f7cb81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sentences[0])\n",
        "other_words = []\n",
        "for x in sentences:\n",
        "  for y in x:\n",
        "    if y[0] not in other_words:\n",
        "      other_words.append(y[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('മഹാത്മാഗാന്ധി', 'N_NNP'), ('രാഷ്ട്രപിതാവ്', 'N_NN'), ('ലക്ഷ്യങ്ങളെല്ലാം', 'N_NN'), ('കര്\\u200d്മ്മഫലത്തിലെത്തിച്ച', 'V_VM_VNF'), ('മഹാൻ', 'N_NN'), ('.', 'RD_PUNC')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0yFhj2QEfj8",
        "colab_type": "code",
        "outputId": "c28d6d4f-81ac-492e-d81b-45e86fe068d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(other_words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by9Lh0jKdex6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence =[]\n",
        "tags = []\n",
        "count = 0\n",
        "c = 0\n",
        "\n",
        "for x in sentences:\n",
        "  s = []\n",
        "  t = []\n",
        "  for y in x:\n",
        "    if len(y)>=2:\n",
        "      s.append(y[0])\n",
        "      t.append(y[1])\n",
        "      \n",
        "  sentence.append((s,t))\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvWtbvvQdox3",
        "colab_type": "code",
        "outputId": "fcb09702-1155-4733-9cde-72cb95aeb5b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sentence[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['മഹാത്മാഗാന്ധി', 'രാഷ്ട്രപിതാവ്', 'ലക്ഷ്യങ്ങളെല്ലാം', 'കര്\\u200d്മ്മഫലത്തിലെത്തിച്ച', 'മഹാൻ', '.'], ['N_NNP', 'N_NN', 'N_NN', 'V_VM_VNF', 'N_NN', 'RD_PUNC'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydzOIXb4duKx",
        "colab_type": "code",
        "outputId": "9d2e4004-4960-4221-8de5-b57d85a0b63b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(sentence))\n",
        "textData = sentence[2500:]\n",
        "training_data = sentence"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y7UkhOed6pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n",
        "    Output: a tensor containing the indexes of the word\"\"\"\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7V6eDvCd_RT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_ix = {} # This is the word dictionary which will contain the index to each word\n",
        "\n",
        "for sent, tags in training_data:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix.keys():\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "for word in other_words:\n",
        "    if word not in word_to_ix.keys():\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "# print(word_to_ix) # Just have a look at what it contains\n",
        "\n",
        "tag_to_ix = {'N_NNP': 0, 'N_NN': 1, 'V_VM_VNF': 2, 'RD_PUNC': 3, 'QT_QTF': 4, 'RB': 5, 'PR_PRF': 6, 'JJ': 7, 'PR_PRP': 8, 'V_VAUX': 9, 'QT_QTO': 10, 'RP_INTF': 11, 'RD_RDF': 12, 'DM_DMD': 13, 'DM_DMR': 14, 'CC_CCD': 15, 'PSP': 16, 'V_VM_VF': 17, 'N_NST': 18, 'CC_CCS': 19, 'RP_NEG': 20, 'V_VM_VINF': 21, 'DM_DMQ': 22, 'PR_PRL': 23, 'V_VM': 24, 'RP_RPD': 25, 'PR_PRC': 26, 'V_VN': 27, 'RP_INJ': 28, 'QT_QTC': 29, 'PR_PRQ': 30,'CC_CCS_UT': 31,'RD_UNK':32}\n",
        "   #{\"DET\": 0, \"NN\": 1, \"V\": 2, \"ADJ\": 3, \"ADV\": 4, \"PRP\": 5, \"PRN\": 6} # This dictionary contains the indices of the tags\n",
        "\n",
        "EMBEDDING_DIM = 64\n",
        "HIDDEN_DIM = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtPBxs27e32O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
        "        \n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaPt1rkleDEb",
        "colab_type": "code",
        "outputId": "79670dc4-b3fb-4c67-d526-bb7278f026ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix.keys()), len(tag_to_ix.keys()))\n",
        "\n",
        "# Define the loss function as the Negative Log Likelihood loss (NLLLoss)\n",
        "loss_function = nn.NLLLoss()\n",
        "\n",
        "# We will be using a simple SGD optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# The test sentence\n",
        "\n",
        "    \n",
        "print(\"Training Started\")\n",
        "for epoch in range(300):\n",
        "    print(\"epoch :\", epoch)\n",
        "    for sentence, tags in training_data[:2500]:\n",
        "        model.zero_grad()\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = prepare_sequence(tags, tag_to_ix)\n",
        "        \n",
        "        tag_scores = model(sentence_in)\n",
        "        \n",
        "        loss = loss_function(tag_scores, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "print(\"Training Finished!!!\\nAgain testing on unknown data\")\n",
        "with torch.no_grad():\n",
        "    for seq in [seq1, seq2]:\n",
        "        inputs = prepare_sequence(seq, word_to_ix)\n",
        "        tag_scores = model(inputs)\n",
        "        _, indices = torch.max(tag_scores, 1)\n",
        "        ret = []\n",
        "        for i in range(len(indices)):\n",
        "            for key, value in tag_to_ix.items():\n",
        "                if indices[i] == value:\n",
        "                    ret.append((seq[i], key))\n",
        "        print(ret)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Started\n",
            "epoch : 0\n",
            "epoch : 1\n",
            "epoch : 2\n",
            "epoch : 3\n",
            "epoch : 4\n",
            "epoch : 5\n",
            "epoch : 6\n",
            "epoch : 7\n",
            "epoch : 8\n",
            "epoch : 9\n",
            "epoch : 10\n",
            "epoch : 11\n",
            "epoch : 12\n",
            "epoch : 13\n",
            "epoch : 14\n",
            "epoch : 15\n",
            "epoch : 16\n",
            "epoch : 17\n",
            "epoch : 18\n",
            "epoch : 19\n",
            "epoch : 20\n",
            "epoch : 21\n",
            "epoch : 22\n",
            "epoch : 23\n",
            "epoch : 24\n",
            "epoch : 25\n",
            "epoch : 26\n",
            "epoch : 27\n",
            "epoch : 28\n",
            "epoch : 29\n",
            "epoch : 30\n",
            "epoch : 31\n",
            "epoch : 32\n",
            "epoch : 33\n",
            "epoch : 34\n",
            "epoch : 35\n",
            "epoch : 36\n",
            "epoch : 37\n",
            "epoch : 38\n",
            "epoch : 39\n",
            "epoch : 40\n",
            "epoch : 41\n",
            "epoch : 42\n",
            "epoch : 43\n",
            "epoch : 44\n",
            "epoch : 45\n",
            "epoch : 46\n",
            "epoch : 47\n",
            "epoch : 48\n",
            "epoch : 49\n",
            "epoch : 50\n",
            "epoch : 51\n",
            "epoch : 52\n",
            "epoch : 53\n",
            "epoch : 54\n",
            "epoch : 55\n",
            "epoch : 56\n",
            "epoch : 57\n",
            "epoch : 58\n",
            "epoch : 59\n",
            "epoch : 60\n",
            "epoch : 61\n",
            "epoch : 62\n",
            "epoch : 63\n",
            "epoch : 64\n",
            "epoch : 65\n",
            "epoch : 66\n",
            "epoch : 67\n",
            "epoch : 68\n",
            "epoch : 69\n",
            "epoch : 70\n",
            "epoch : 71\n",
            "epoch : 72\n",
            "epoch : 73\n",
            "epoch : 74\n",
            "epoch : 75\n",
            "epoch : 76\n",
            "epoch : 77\n",
            "epoch : 78\n",
            "epoch : 79\n",
            "epoch : 80\n",
            "epoch : 81\n",
            "epoch : 82\n",
            "epoch : 83\n",
            "epoch : 84\n",
            "epoch : 85\n",
            "epoch : 86\n",
            "epoch : 87\n",
            "epoch : 88\n",
            "epoch : 89\n",
            "epoch : 90\n",
            "epoch : 91\n",
            "epoch : 92\n",
            "epoch : 93\n",
            "epoch : 94\n",
            "epoch : 95\n",
            "epoch : 96\n",
            "epoch : 97\n",
            "epoch : 98\n",
            "epoch : 99\n",
            "epoch : 100\n",
            "epoch : 101\n",
            "epoch : 102\n",
            "epoch : 103\n",
            "epoch : 104\n",
            "epoch : 105\n",
            "epoch : 106\n",
            "epoch : 107\n",
            "epoch : 108\n",
            "epoch : 109\n",
            "epoch : 110\n",
            "epoch : 111\n",
            "epoch : 112\n",
            "epoch : 113\n",
            "epoch : 114\n",
            "epoch : 115\n",
            "epoch : 116\n",
            "epoch : 117\n",
            "epoch : 118\n",
            "epoch : 119\n",
            "epoch : 120\n",
            "epoch : 121\n",
            "epoch : 122\n",
            "epoch : 123\n",
            "epoch : 124\n",
            "epoch : 125\n",
            "epoch : 126\n",
            "epoch : 127\n",
            "epoch : 128\n",
            "epoch : 129\n",
            "epoch : 130\n",
            "epoch : 131\n",
            "epoch : 132\n",
            "epoch : 133\n",
            "epoch : 134\n",
            "epoch : 135\n",
            "epoch : 136\n",
            "epoch : 137\n",
            "epoch : 138\n",
            "epoch : 139\n",
            "epoch : 140\n",
            "epoch : 141\n",
            "epoch : 142\n",
            "epoch : 143\n",
            "epoch : 144\n",
            "epoch : 145\n",
            "epoch : 146\n",
            "epoch : 147\n",
            "epoch : 148\n",
            "epoch : 149\n",
            "epoch : 150\n",
            "epoch : 151\n",
            "epoch : 152\n",
            "epoch : 153\n",
            "epoch : 154\n",
            "epoch : 155\n",
            "epoch : 156\n",
            "epoch : 157\n",
            "epoch : 158\n",
            "epoch : 159\n",
            "epoch : 160\n",
            "epoch : 161\n",
            "epoch : 162\n",
            "epoch : 163\n",
            "epoch : 164\n",
            "epoch : 165\n",
            "epoch : 166\n",
            "epoch : 167\n",
            "epoch : 168\n",
            "epoch : 169\n",
            "epoch : 170\n",
            "epoch : 171\n",
            "epoch : 172\n",
            "epoch : 173\n",
            "epoch : 174\n",
            "epoch : 175\n",
            "epoch : 176\n",
            "epoch : 177\n",
            "epoch : 178\n",
            "epoch : 179\n",
            "epoch : 180\n",
            "epoch : 181\n",
            "epoch : 182\n",
            "epoch : 183\n",
            "epoch : 184\n",
            "epoch : 185\n",
            "epoch : 186\n",
            "epoch : 187\n",
            "epoch : 188\n",
            "epoch : 189\n",
            "epoch : 190\n",
            "epoch : 191\n",
            "epoch : 192\n",
            "epoch : 193\n",
            "epoch : 194\n",
            "epoch : 195\n",
            "epoch : 196\n",
            "epoch : 197\n",
            "epoch : 198\n",
            "epoch : 199\n",
            "epoch : 200\n",
            "epoch : 201\n",
            "epoch : 202\n",
            "epoch : 203\n",
            "epoch : 204\n",
            "epoch : 205\n",
            "epoch : 206\n",
            "epoch : 207\n",
            "epoch : 208\n",
            "epoch : 209\n",
            "epoch : 210\n",
            "epoch : 211\n",
            "epoch : 212\n",
            "epoch : 213\n",
            "epoch : 214\n",
            "epoch : 215\n",
            "epoch : 216\n",
            "epoch : 217\n",
            "epoch : 218\n",
            "epoch : 219\n",
            "epoch : 220\n",
            "epoch : 221\n",
            "epoch : 222\n",
            "epoch : 223\n",
            "epoch : 224\n",
            "epoch : 225\n",
            "epoch : 226\n",
            "epoch : 227\n",
            "epoch : 228\n",
            "epoch : 229\n",
            "epoch : 230\n",
            "epoch : 231\n",
            "epoch : 232\n",
            "epoch : 233\n",
            "epoch : 234\n",
            "epoch : 235\n",
            "epoch : 236\n",
            "epoch : 237\n",
            "epoch : 238\n",
            "epoch : 239\n",
            "epoch : 240\n",
            "epoch : 241\n",
            "epoch : 242\n",
            "epoch : 243\n",
            "epoch : 244\n",
            "epoch : 245\n",
            "epoch : 246\n",
            "epoch : 247\n",
            "epoch : 248\n",
            "epoch : 249\n",
            "epoch : 250\n",
            "epoch : 251\n",
            "epoch : 252\n",
            "epoch : 253\n",
            "epoch : 254\n",
            "epoch : 255\n",
            "epoch : 256\n",
            "epoch : 257\n",
            "epoch : 258\n",
            "epoch : 259\n",
            "epoch : 260\n",
            "epoch : 261\n",
            "epoch : 262\n",
            "epoch : 263\n",
            "epoch : 264\n",
            "epoch : 265\n",
            "epoch : 266\n",
            "epoch : 267\n",
            "epoch : 268\n",
            "epoch : 269\n",
            "epoch : 270\n",
            "epoch : 271\n",
            "epoch : 272\n",
            "epoch : 273\n",
            "epoch : 274\n",
            "epoch : 275\n",
            "epoch : 276\n",
            "epoch : 277\n",
            "epoch : 278\n",
            "epoch : 279\n",
            "epoch : 280\n",
            "epoch : 281\n",
            "epoch : 282\n",
            "epoch : 283\n",
            "epoch : 284\n",
            "epoch : 285\n",
            "epoch : 286\n",
            "epoch : 287\n",
            "epoch : 288\n",
            "epoch : 289\n",
            "epoch : 290\n",
            "epoch : 291\n",
            "epoch : 292\n",
            "epoch : 293\n",
            "epoch : 294\n",
            "epoch : 295\n",
            "epoch : 296\n",
            "epoch : 297\n",
            "epoch : 298\n",
            "epoch : 299\n",
            "Training Finished!!!\n",
            "Again testing on unknown data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7a080a539927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Finished!!!\\nAgain testing on unknown data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seq1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LsjWIESYyMc",
        "colab_type": "code",
        "outputId": "7975161f-683a-44ed-9a05-39e3a994d144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(training_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwJs-r3TelJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),'/content/drive/My Drive/NLP Research/s2.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx447Ef3zy4U",
        "colab_type": "code",
        "outputId": "ae9dcb32-db2f-454c-b128-bc4df5cb8fda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "#seq1 = 'മഹാത്മാഗാന്ധി  രാഷ്ട്രപിതാവ് ലക്ഷ്യങ്ങളെല്ലാം കര്\\u200d്മ്മഫലത്തിലെത്തിച്ച മഹാൻ .'.split()\n",
        "with torch.no_grad():\n",
        "    for seq in textData:\n",
        "        inputs = prepare_sequence(seq, word_to_ix)\n",
        "        tag_scores = model(inputs)\n",
        "        _, indices = torch.max(tag_scores, 1)\n",
        "        ret = []\n",
        "        for i in range(len(indices)):\n",
        "            for key, value in tag_to_ix.items():\n",
        "                if indices[i] == value:\n",
        "                    ret.append((seq[i], key))\n",
        "        print(ret)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-76dc5ad90bba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtextData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-121-cbe7f0b91c8a>\u001b[0m in \u001b[0;36mprepare_sequence\u001b[0;34m(seq, to_ix)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n\u001b[1;32m      5\u001b[0m     Output: a tensor containing the indexes of the word\"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mto_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-121-cbe7f0b91c8a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n\u001b[1;32m      5\u001b[0m     Output: a tensor containing the indexes of the word\"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mto_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inDiguLFzzXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence2 =[]\n",
        "tags = []\n",
        "count = 0\n",
        "c = 0\n",
        "\n",
        "for x in sentences[2500:]:\n",
        "  s = []\n",
        "  t = []\n",
        "  for y in x:\n",
        "    if len(y)>=2:\n",
        "      s.append(y[0])\n",
        "      t.append(y[1])\n",
        "      \n",
        "  sentence2.append((s,t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcAag_OMUhYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(sentence2[0])\n",
        "testData2 = []\n",
        "for x in testData[:500]:\n",
        "  sub = \"\"\n",
        "  for y in x[0]:\n",
        "    sub+=y\n",
        "    sub+=\" \"\n",
        "  testData2.append(sub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeWS-mNTXAPl",
        "colab_type": "code",
        "outputId": "5e17eae2-71cf-4db6-b649-aa508e50ba2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "print(testData[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c33c63fb1624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IoWaBS5VBRb",
        "colab_type": "code",
        "outputId": "32fffb59-8ded-4a89-d524-c60e6a9925eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "seq1 =['അവര്‍ ബക്കററ് പലതവണ താഴേക്കിറക്കിയതാണു് .'.split()] \n",
        "#seq1 = []\n",
        "\n",
        "with torch.no_grad():\n",
        "      for seq in seq1:\n",
        "\n",
        "          inputs = prepare_sequence(seq, word_to_ix)\n",
        "          tag_scores = model(inputs)\n",
        "          _, indices = torch.max(tag_scores, 1)\n",
        "          ret = []\n",
        "          for i in range(len(indices)):\n",
        "              for key, value in tag_to_ix.items():\n",
        "                  if indices[i] == value:\n",
        "                      ret.append((seq[i], key))\n",
        "          print(ret)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9207d25cfdf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#seq1 = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt9O5zLWV20M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}