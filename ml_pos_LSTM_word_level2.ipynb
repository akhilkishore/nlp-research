{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_pos_LSTM_word_level",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwQXSzkodJtJ",
        "colab_type": "code",
        "outputId": "cc9cc7ed-5362-40f1-ebb4-f54f392b1735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75ilch-_dSAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgwoW8EldSYV",
        "colab_type": "code",
        "outputId": "0f58a6cc-2576-4418-847c-3ce289b32ec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "f = open(\"/content/drive/My Drive/Malayalam_NLP/Data/pos_tagged_data/Malayalam_Tagged_Data.txt\",\"r\")\n",
        "data = f.read()\n",
        "print(len(data))\n",
        "data = data.split(\".        \\RD_PUNC\")\n",
        "all_sent = []\n",
        "for x in data:\n",
        "    x = x.split(\"\\n\")\n",
        "    v = []\n",
        "    for y in x:\n",
        "        if y != \"\":\n",
        "            y = y.replace(\"\\\\\",\"\")\n",
        "            y = y.split(\"        \")\n",
        "            v.append( (y[0],y[1]) )\n",
        "    v.append(('.','RD_PUNC'))\n",
        "    all_sent.append(v)\n",
        "del data\n",
        "sentences = all_sent\n",
        "del all_sent\n",
        "print(len(sentences))\n",
        "\n",
        "sentences = sentences[:10000]\n",
        "print(len(sentences))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-eab5e96fd19c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Malayalam_NLP/Data/pos_tagged_data/Malayalam_Tagged_Data.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".        \\RD_PUNC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spFNijStdbBf",
        "colab_type": "code",
        "outputId": "583ef40b-c965-451a-f331-8229a1eb1298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sentences[0])\n",
        "other_words = []\n",
        "for x in sentences:\n",
        "  for y in x:\n",
        "    if y[0] not in other_words:\n",
        "      other_words.append(y[0])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('മഹാത്മാഗാന്ധി', 'N_NNP'), ('രാഷ്ട്രപിതാവ്', 'N_NN'), ('ലക്ഷ്യങ്ങളെല്ലാം', 'N_NN'), ('കര്\\u200d്മ്മഫലത്തിലെത്തിച്ച', 'V_VM_VNF'), ('മഹാൻ', 'N_NN'), ('.', 'RD_PUNC')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0yFhj2QEfj8",
        "colab_type": "code",
        "outputId": "902757de-063d-4466-ba33-9e75b2428930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(other_words))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by9Lh0jKdex6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence =[]\n",
        "tags = []\n",
        "count = 0\n",
        "c = 0\n",
        "\n",
        "for x in sentences:\n",
        "  s = []\n",
        "  t = []\n",
        "  for y in x:\n",
        "    if len(y)>=2:\n",
        "      s.append(y[0])\n",
        "      t.append(y[1])\n",
        "      \n",
        "  sentence.append((s,t))\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvWtbvvQdox3",
        "colab_type": "code",
        "outputId": "1696276a-cc3b-4abe-b3c7-5391d88cf4f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sentence[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['മഹാത്മാഗാന്ധി', 'രാഷ്ട്രപിതാവ്', 'ലക്ഷ്യങ്ങളെല്ലാം', 'കര്\\u200d്മ്മഫലത്തിലെത്തിച്ച', 'മഹാൻ', '.'], ['N_NNP', 'N_NN', 'N_NN', 'V_VM_VNF', 'N_NN', 'RD_PUNC'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD7HBfboH4QO",
        "colab_type": "code",
        "outputId": "b73c9f47-b9c1-4b2f-8771-4ee98447bd83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "data = []\n",
        "tagged_data = []\n",
        "for x in sentence:\n",
        "  data.append(x[0])\n",
        "  tagged_data.append(x[1])\n",
        "\n",
        "print(data[10])\n",
        "print(tagged_data[10])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['അതിനു', 'പുറമെ', 'പ്രത്യക്ഷമായിത്തന്നെ', 'വിദ്യാഭ്യാസം', 'സ്വയംപര്യാപ്തമാക്കാന്\\u200dവേണ്ടി', 'വ്യവസായാഭ്യസനവുമായി', 'ഒന്നിച്ചുതുടര്\\u200dന്നുകൊണ്ടു', 'പോകേണ്ടുന്നതിന്\\u200dറെ', 'ആവശ്യകത', 'കൂടിഈ', 'രാജ്യത്തുണ്ട്', '.']\n",
            "['DM_DMD', 'PSP', 'RB', 'N_NN', 'V_VM_VNF', 'RB', 'V_VM_VNF', 'N_NN', 'N_NN', 'DM_DMD', 'V_VAUX', 'RD_PUNC']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1Lz59r91rtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i6NAC5GIGrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "(train_sentences, \n",
        " test_sentences, \n",
        " train_tags, \n",
        " test_tags) = train_test_split(data, tagged_data, test_size=0.2)\n",
        "\n",
        "words, tags = set([]), set([])\n",
        " \n",
        "for s in train_sentences:\n",
        "    for w in s:\n",
        "        words.add(w.lower())\n",
        " \n",
        "for ts in train_tags:\n",
        "    for t in ts:\n",
        "        tags.add(t)\n",
        " \n",
        "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
        "word2index['-PAD-'] = 0  # The special value used for padding\n",
        "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
        " \n",
        "tag2index = {t: i + 1 for i, t in enumerate(list(tags))}\n",
        "tag2index['-PAD-'] = 0  # The special value used to padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2VPkrpUIGwP",
        "colab_type": "code",
        "outputId": "a597cd45-fb1f-4e92-eac1-bc0992a495a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "train_sentences_X, test_sentences_X, train_tags_y, test_tags_y = [], [], [], []\n",
        " \n",
        "for s in train_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    train_sentences_X.append(s_int)\n",
        " \n",
        "for s in test_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    test_sentences_X.append(s_int)\n",
        " \n",
        "for s in train_tags:\n",
        "    train_tags_y.append([tag2index[t] for t in s])\n",
        " \n",
        "for s in test_tags:\n",
        "    test_tags_y.append([tag2index[t] for t in s])\n",
        " \n",
        "print(train_sentences_X[0])\n",
        "print(test_sentences_X[0])\n",
        "print(train_tags_y[0])\n",
        "print(test_tags_y[0])\n",
        " "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[51983, 24896, 50822, 33916, 56286, 13676, 43706, 9641, 62991, 48556, 10743, 8254, 42844]\n",
            "[46830, 44209, 26797, 40981, 1, 45328, 1, 17755, 23259, 35649, 1, 1, 60949, 42844]\n",
            "[34, 9, 34, 35, 34, 34, 21, 34, 34, 34, 21, 2, 33]\n",
            "[23, 34, 34, 34, 32, 32, 32, 34, 34, 9, 34, 28, 2, 33]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upEK02yuIGys",
        "colab_type": "code",
        "outputId": "0018ae3a-11e1-4e2a-fdff-d9c20fced4f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
        "print(MAX_LENGTH)  # 271\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        " \n",
        "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        " \n",
        "print(train_sentences_X[0])\n",
        "print(test_sentences_X[0])\n",
        "print(train_tags_y[0])\n",
        "print(test_tags_y[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-0c703271449a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMAX_LENGTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sentences_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 271\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SQCLwuoJ_s9",
        "colab_type": "code",
        "outputId": "f8e446f5-9698-429a-8a53-5c876c1e6408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from keras.optimizers import Adam\n",
        " \n",
        " \n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "model.add(Embedding(len(word2index), 128))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(tag2index))))\n",
        "model.add(Activation('softmax'))\n",
        " \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(0.001),\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model.summary()\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 62, 128)           4197120   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 62, 512)           788480    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 62, 36)            18468     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 62, 36)            0         \n",
            "=================================================================\n",
            "Total params: 5,004,068\n",
            "Trainable params: 5,004,068\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhP-jhRiJ_1v",
        "colab_type": "code",
        "outputId": "41f45de6-6faf-4672-acfd-6c458a0ee48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "def to_categorical(sequences, categories):\n",
        "    cat_sequences = []\n",
        "    for s in sequences:\n",
        "        cats = []\n",
        "        for item in s:\n",
        "            cats.append(np.zeros(categories))\n",
        "            cats[-1][item] = 1.0\n",
        "        cat_sequences.append(cats)\n",
        "    return np.array(cat_sequences)\n",
        " \n",
        "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
        "print(cat_train_tags_y[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MibYIapaKZ3b",
        "colab_type": "code",
        "outputId": "81795eb4-cdcf-4b66-fe0a-fba520020aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=128, epochs=10, validation_split=0.2, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6400 samples, validate on 1600 samples\n",
            "Epoch 1/10\n",
            "6400/6400 [==============================] - 82s 13ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.2073 - val_acc: 0.9587\n",
            "Epoch 2/10\n",
            "6400/6400 [==============================] - 82s 13ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 0.2139 - val_acc: 0.9599\n",
            "Epoch 3/10\n",
            "6400/6400 [==============================] - 81s 13ms/step - loss: 0.0023 - acc: 0.9997 - val_loss: 0.2090 - val_acc: 0.9587\n",
            "Epoch 4/10\n",
            "6400/6400 [==============================] - 82s 13ms/step - loss: 0.0020 - acc: 0.9998 - val_loss: 0.2181 - val_acc: 0.9589\n",
            "Epoch 5/10\n",
            "6400/6400 [==============================] - 82s 13ms/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.2231 - val_acc: 0.9595\n",
            "Epoch 6/10\n",
            "6400/6400 [==============================] - 82s 13ms/step - loss: 0.0015 - acc: 0.9998 - val_loss: 0.2225 - val_acc: 0.9590\n",
            "Epoch 7/10\n",
            "6400/6400 [==============================] - 82s 13ms/step - loss: 0.0014 - acc: 0.9999 - val_loss: 0.2254 - val_acc: 0.9590\n",
            "Epoch 8/10\n",
            "6400/6400 [==============================] - 82s 13ms/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.2270 - val_acc: 0.9591\n",
            "Epoch 9/10\n",
            "6400/6400 [==============================] - 82s 13ms/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.2284 - val_acc: 0.9593\n",
            "Epoch 10/10\n",
            "6400/6400 [==============================] - 82s 13ms/step - loss: 9.7805e-04 - acc: 0.9999 - val_loss: 0.2352 - val_acc: 0.9589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7d237cbb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txi01KmbKaE0",
        "colab_type": "code",
        "outputId": "584b73f8-5ec7-4c24-913b-50fd6d06dfc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
        "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")   # acc: 99.09751977804825\n",
        "#https://nlpforhackers.io/lstm-pos-tagger-keras/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 6s 3ms/step\n",
            "acc: 96.04677419662475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7sGLJNaKaOQ",
        "colab_type": "code",
        "outputId": "9a451c75-97cd-4c24-ab1a-2be12de9e28f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\t\n",
        "test_samples = [\n",
        "    \"എന്നാൽ ഏതാനം സമയം ചിത്രങ്ങളിൽ ശ്രദ്ധിച്ചിരുന്ന രവിവർമ്മക്ക്‌ അത്‌ വളരെ എളുപ്പം മനസ്സിലാക്കാൻ കഴിഞ്ഞു .\".split()\n",
        "#    \"I was running every day for a month .\".split()\n",
        "]\n",
        "print(test_samples)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['എന്നാൽ', 'ഏതാനം', 'സമയം', 'ചിത്രങ്ങളിൽ', 'ശ്രദ്ധിച്ചിരുന്ന', 'രവിവർമ്മക്ക്\\u200c', 'അത്\\u200c', 'വളരെ', 'എളുപ്പം', 'മനസ്സിലാക്കാൻ', 'കഴിഞ്ഞു', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_N0ZLrHKaMh",
        "colab_type": "code",
        "outputId": "b6ee37bc-f6fe-42ed-9812-3d2666f89c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "test_samples_X = []\n",
        "for s in test_samples:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        "    test_samples_X.append(s_int)\n",
        " \n",
        "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
        "print(test_samples_X)\n",
        "predictions = model.predict(test_samples_X)\n",
        "\n",
        "def logits_to_tokens(sequences, index):\n",
        "    token_sequences = []\n",
        "    for categorical_sequence in sequences:\n",
        "        token_sequence = []\n",
        "        for categorical in categorical_sequence:\n",
        "            token_sequence.append(index[np.argmax(categorical)])\n",
        " \n",
        "        token_sequences.append(token_sequence)\n",
        " \n",
        "    return token_sequences\n",
        "\n",
        "\n",
        "print(logits_to_tokens(predictions, {i: t for t, i in tag2index.items()}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    1     1 15897     1     1     1     1 18872 17202     1   308  1621\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0]]\n",
            "[['N_NN', 'N_NN', 'N_NN', 'N_NN', 'N_NN', 'N_NN', 'N_NN', 'RP_INTF', 'RB', 'N_NN', 'V_VM_VF', 'RD_PUNC', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydzOIXb4duKx",
        "colab_type": "code",
        "outputId": "9d2e4004-4960-4221-8de5-b57d85a0b63b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(sentence))\n",
        "textData = sentence[2500:]\n",
        "training_data = sentence"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y7UkhOed6pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n",
        "    Output: a tensor containing the indexes of the word\"\"\"\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7V6eDvCd_RT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_ix = {} # This is the word dictionary which will contain the index to each word\n",
        "\n",
        "for sent, tags in training_data:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix.keys():\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "for word in other_words:\n",
        "    if word not in word_to_ix.keys():\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "# print(word_to_ix) # Just have a look at what it contains\n",
        "\n",
        "tag_to_ix = {'N_NNP': 0, 'N_NN': 1, 'V_VM_VNF': 2, 'RD_PUNC': 3, 'QT_QTF': 4, 'RB': 5, 'PR_PRF': 6, 'JJ': 7, 'PR_PRP': 8, 'V_VAUX': 9, 'QT_QTO': 10, 'RP_INTF': 11, 'RD_RDF': 12, 'DM_DMD': 13, 'DM_DMR': 14, 'CC_CCD': 15, 'PSP': 16, 'V_VM_VF': 17, 'N_NST': 18, 'CC_CCS': 19, 'RP_NEG': 20, 'V_VM_VINF': 21, 'DM_DMQ': 22, 'PR_PRL': 23, 'V_VM': 24, 'RP_RPD': 25, 'PR_PRC': 26, 'V_VN': 27, 'RP_INJ': 28, 'QT_QTC': 29, 'PR_PRQ': 30,'CC_CCS_UT': 31,'RD_UNK':32}\n",
        "   #{\"DET\": 0, \"NN\": 1, \"V\": 2, \"ADJ\": 3, \"ADV\": 4, \"PRP\": 5, \"PRN\": 6} # This dictionary contains the indices of the tags\n",
        "\n",
        "EMBEDDING_DIM = 64\n",
        "HIDDEN_DIM = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtPBxs27e32O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
        "        \n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaPt1rkleDEb",
        "colab_type": "code",
        "outputId": "79670dc4-b3fb-4c67-d526-bb7278f026ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix.keys()), len(tag_to_ix.keys()))\n",
        "\n",
        "# Define the loss function as the Negative Log Likelihood loss (NLLLoss)\n",
        "loss_function = nn.NLLLoss()\n",
        "\n",
        "# We will be using a simple SGD optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# The test sentence\n",
        "\n",
        "    \n",
        "print(\"Training Started\")\n",
        "for epoch in range(300):\n",
        "    print(\"epoch :\", epoch)\n",
        "    for sentence, tags in training_data[:2500]:\n",
        "        model.zero_grad()\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = prepare_sequence(tags, tag_to_ix)\n",
        "        \n",
        "        tag_scores = model(sentence_in)\n",
        "        \n",
        "        loss = loss_function(tag_scores, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "print(\"Training Finished!!!\\nAgain testing on unknown data\")\n",
        "with torch.no_grad():\n",
        "    for seq in [seq1, seq2]:\n",
        "        inputs = prepare_sequence(seq, word_to_ix)\n",
        "        tag_scores = model(inputs)\n",
        "        _, indices = torch.max(tag_scores, 1)\n",
        "        ret = []\n",
        "        for i in range(len(indices)):\n",
        "            for key, value in tag_to_ix.items():\n",
        "                if indices[i] == value:\n",
        "                    ret.append((seq[i], key))\n",
        "        print(ret)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Started\n",
            "epoch : 0\n",
            "epoch : 1\n",
            "epoch : 2\n",
            "epoch : 3\n",
            "epoch : 4\n",
            "epoch : 5\n",
            "epoch : 6\n",
            "epoch : 7\n",
            "epoch : 8\n",
            "epoch : 9\n",
            "epoch : 10\n",
            "epoch : 11\n",
            "epoch : 12\n",
            "epoch : 13\n",
            "epoch : 14\n",
            "epoch : 15\n",
            "epoch : 16\n",
            "epoch : 17\n",
            "epoch : 18\n",
            "epoch : 19\n",
            "epoch : 20\n",
            "epoch : 21\n",
            "epoch : 22\n",
            "epoch : 23\n",
            "epoch : 24\n",
            "epoch : 25\n",
            "epoch : 26\n",
            "epoch : 27\n",
            "epoch : 28\n",
            "epoch : 29\n",
            "epoch : 30\n",
            "epoch : 31\n",
            "epoch : 32\n",
            "epoch : 33\n",
            "epoch : 34\n",
            "epoch : 35\n",
            "epoch : 36\n",
            "epoch : 37\n",
            "epoch : 38\n",
            "epoch : 39\n",
            "epoch : 40\n",
            "epoch : 41\n",
            "epoch : 42\n",
            "epoch : 43\n",
            "epoch : 44\n",
            "epoch : 45\n",
            "epoch : 46\n",
            "epoch : 47\n",
            "epoch : 48\n",
            "epoch : 49\n",
            "epoch : 50\n",
            "epoch : 51\n",
            "epoch : 52\n",
            "epoch : 53\n",
            "epoch : 54\n",
            "epoch : 55\n",
            "epoch : 56\n",
            "epoch : 57\n",
            "epoch : 58\n",
            "epoch : 59\n",
            "epoch : 60\n",
            "epoch : 61\n",
            "epoch : 62\n",
            "epoch : 63\n",
            "epoch : 64\n",
            "epoch : 65\n",
            "epoch : 66\n",
            "epoch : 67\n",
            "epoch : 68\n",
            "epoch : 69\n",
            "epoch : 70\n",
            "epoch : 71\n",
            "epoch : 72\n",
            "epoch : 73\n",
            "epoch : 74\n",
            "epoch : 75\n",
            "epoch : 76\n",
            "epoch : 77\n",
            "epoch : 78\n",
            "epoch : 79\n",
            "epoch : 80\n",
            "epoch : 81\n",
            "epoch : 82\n",
            "epoch : 83\n",
            "epoch : 84\n",
            "epoch : 85\n",
            "epoch : 86\n",
            "epoch : 87\n",
            "epoch : 88\n",
            "epoch : 89\n",
            "epoch : 90\n",
            "epoch : 91\n",
            "epoch : 92\n",
            "epoch : 93\n",
            "epoch : 94\n",
            "epoch : 95\n",
            "epoch : 96\n",
            "epoch : 97\n",
            "epoch : 98\n",
            "epoch : 99\n",
            "epoch : 100\n",
            "epoch : 101\n",
            "epoch : 102\n",
            "epoch : 103\n",
            "epoch : 104\n",
            "epoch : 105\n",
            "epoch : 106\n",
            "epoch : 107\n",
            "epoch : 108\n",
            "epoch : 109\n",
            "epoch : 110\n",
            "epoch : 111\n",
            "epoch : 112\n",
            "epoch : 113\n",
            "epoch : 114\n",
            "epoch : 115\n",
            "epoch : 116\n",
            "epoch : 117\n",
            "epoch : 118\n",
            "epoch : 119\n",
            "epoch : 120\n",
            "epoch : 121\n",
            "epoch : 122\n",
            "epoch : 123\n",
            "epoch : 124\n",
            "epoch : 125\n",
            "epoch : 126\n",
            "epoch : 127\n",
            "epoch : 128\n",
            "epoch : 129\n",
            "epoch : 130\n",
            "epoch : 131\n",
            "epoch : 132\n",
            "epoch : 133\n",
            "epoch : 134\n",
            "epoch : 135\n",
            "epoch : 136\n",
            "epoch : 137\n",
            "epoch : 138\n",
            "epoch : 139\n",
            "epoch : 140\n",
            "epoch : 141\n",
            "epoch : 142\n",
            "epoch : 143\n",
            "epoch : 144\n",
            "epoch : 145\n",
            "epoch : 146\n",
            "epoch : 147\n",
            "epoch : 148\n",
            "epoch : 149\n",
            "epoch : 150\n",
            "epoch : 151\n",
            "epoch : 152\n",
            "epoch : 153\n",
            "epoch : 154\n",
            "epoch : 155\n",
            "epoch : 156\n",
            "epoch : 157\n",
            "epoch : 158\n",
            "epoch : 159\n",
            "epoch : 160\n",
            "epoch : 161\n",
            "epoch : 162\n",
            "epoch : 163\n",
            "epoch : 164\n",
            "epoch : 165\n",
            "epoch : 166\n",
            "epoch : 167\n",
            "epoch : 168\n",
            "epoch : 169\n",
            "epoch : 170\n",
            "epoch : 171\n",
            "epoch : 172\n",
            "epoch : 173\n",
            "epoch : 174\n",
            "epoch : 175\n",
            "epoch : 176\n",
            "epoch : 177\n",
            "epoch : 178\n",
            "epoch : 179\n",
            "epoch : 180\n",
            "epoch : 181\n",
            "epoch : 182\n",
            "epoch : 183\n",
            "epoch : 184\n",
            "epoch : 185\n",
            "epoch : 186\n",
            "epoch : 187\n",
            "epoch : 188\n",
            "epoch : 189\n",
            "epoch : 190\n",
            "epoch : 191\n",
            "epoch : 192\n",
            "epoch : 193\n",
            "epoch : 194\n",
            "epoch : 195\n",
            "epoch : 196\n",
            "epoch : 197\n",
            "epoch : 198\n",
            "epoch : 199\n",
            "epoch : 200\n",
            "epoch : 201\n",
            "epoch : 202\n",
            "epoch : 203\n",
            "epoch : 204\n",
            "epoch : 205\n",
            "epoch : 206\n",
            "epoch : 207\n",
            "epoch : 208\n",
            "epoch : 209\n",
            "epoch : 210\n",
            "epoch : 211\n",
            "epoch : 212\n",
            "epoch : 213\n",
            "epoch : 214\n",
            "epoch : 215\n",
            "epoch : 216\n",
            "epoch : 217\n",
            "epoch : 218\n",
            "epoch : 219\n",
            "epoch : 220\n",
            "epoch : 221\n",
            "epoch : 222\n",
            "epoch : 223\n",
            "epoch : 224\n",
            "epoch : 225\n",
            "epoch : 226\n",
            "epoch : 227\n",
            "epoch : 228\n",
            "epoch : 229\n",
            "epoch : 230\n",
            "epoch : 231\n",
            "epoch : 232\n",
            "epoch : 233\n",
            "epoch : 234\n",
            "epoch : 235\n",
            "epoch : 236\n",
            "epoch : 237\n",
            "epoch : 238\n",
            "epoch : 239\n",
            "epoch : 240\n",
            "epoch : 241\n",
            "epoch : 242\n",
            "epoch : 243\n",
            "epoch : 244\n",
            "epoch : 245\n",
            "epoch : 246\n",
            "epoch : 247\n",
            "epoch : 248\n",
            "epoch : 249\n",
            "epoch : 250\n",
            "epoch : 251\n",
            "epoch : 252\n",
            "epoch : 253\n",
            "epoch : 254\n",
            "epoch : 255\n",
            "epoch : 256\n",
            "epoch : 257\n",
            "epoch : 258\n",
            "epoch : 259\n",
            "epoch : 260\n",
            "epoch : 261\n",
            "epoch : 262\n",
            "epoch : 263\n",
            "epoch : 264\n",
            "epoch : 265\n",
            "epoch : 266\n",
            "epoch : 267\n",
            "epoch : 268\n",
            "epoch : 269\n",
            "epoch : 270\n",
            "epoch : 271\n",
            "epoch : 272\n",
            "epoch : 273\n",
            "epoch : 274\n",
            "epoch : 275\n",
            "epoch : 276\n",
            "epoch : 277\n",
            "epoch : 278\n",
            "epoch : 279\n",
            "epoch : 280\n",
            "epoch : 281\n",
            "epoch : 282\n",
            "epoch : 283\n",
            "epoch : 284\n",
            "epoch : 285\n",
            "epoch : 286\n",
            "epoch : 287\n",
            "epoch : 288\n",
            "epoch : 289\n",
            "epoch : 290\n",
            "epoch : 291\n",
            "epoch : 292\n",
            "epoch : 293\n",
            "epoch : 294\n",
            "epoch : 295\n",
            "epoch : 296\n",
            "epoch : 297\n",
            "epoch : 298\n",
            "epoch : 299\n",
            "Training Finished!!!\n",
            "Again testing on unknown data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7a080a539927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Finished!!!\\nAgain testing on unknown data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seq1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LsjWIESYyMc",
        "colab_type": "code",
        "outputId": "7975161f-683a-44ed-9a05-39e3a994d144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(training_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwJs-r3TelJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.save(model.state_dict(),'/content/drive/My Drive/NLP Research/s2.model')\n",
        "torch.save(model.state_dict(),'/content/drive/My Drive/NLP Research/s2.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx447Ef3zy4U",
        "colab_type": "code",
        "outputId": "ae9dcb32-db2f-454c-b128-bc4df5cb8fda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "#seq1 = 'മഹാത്മാഗാന്ധി  രാഷ്ട്രപിതാവ് ലക്ഷ്യങ്ങളെല്ലാം കര്\\u200d്മ്മഫലത്തിലെത്തിച്ച മഹാൻ .'.split()\n",
        "with torch.no_grad():\n",
        "    for seq in textData:\n",
        "        inputs = prepare_sequence(seq, word_to_ix)\n",
        "        tag_scores = model(inputs)\n",
        "        _, indices = torch.max(tag_scores, 1)\n",
        "        ret = []\n",
        "        for i in range(len(indices)):\n",
        "            for key, value in tag_to_ix.items():\n",
        "                if indices[i] == value:\n",
        "                    ret.append((seq[i], key))\n",
        "        print(ret)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-76dc5ad90bba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtextData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-121-cbe7f0b91c8a>\u001b[0m in \u001b[0;36mprepare_sequence\u001b[0;34m(seq, to_ix)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n\u001b[1;32m      5\u001b[0m     Output: a tensor containing the indexes of the word\"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mto_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-121-cbe7f0b91c8a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n\u001b[1;32m      5\u001b[0m     Output: a tensor containing the indexes of the word\"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mto_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inDiguLFzzXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence2 =[]\n",
        "tags = []\n",
        "count = 0\n",
        "c = 0\n",
        "\n",
        "for x in sentences[2500:]:\n",
        "  s = []\n",
        "  t = []\n",
        "  for y in x:\n",
        "    if len(y)>=2:\n",
        "      s.append(y[0])\n",
        "      t.append(y[1])\n",
        "      \n",
        "  sentence2.append((s,t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcAag_OMUhYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(sentence2[0])\n",
        "testData2 = []\n",
        "for x in testData[:500]:\n",
        "  sub = \"\"\n",
        "  for y in x[0]:\n",
        "    sub+=y\n",
        "    sub+=\" \"\n",
        "  testData2.append(sub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeWS-mNTXAPl",
        "colab_type": "code",
        "outputId": "5e17eae2-71cf-4db6-b649-aa508e50ba2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "print(testData[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c33c63fb1624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IoWaBS5VBRb",
        "colab_type": "code",
        "outputId": "32fffb59-8ded-4a89-d524-c60e6a9925eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "seq1 =['അവര്‍ ബക്കററ് പലതവണ താഴേക്കിറക്കിയതാണു് .'.split()] \n",
        "#seq1 = []\n",
        "\n",
        "with torch.no_grad():\n",
        "      for seq in seq1:\n",
        "\n",
        "          inputs = prepare_sequence(seq, word_to_ix)\n",
        "          tag_scores = model(inputs)\n",
        "          _, indices = torch.max(tag_scores, 1)\n",
        "          ret = []\n",
        "          for i in range(len(indices)):\n",
        "              for key, value in tag_to_ix.items():\n",
        "                  if indices[i] == value:\n",
        "                      ret.append((seq[i], key))\n",
        "          print(ret)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9207d25cfdf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#seq1 = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt9O5zLWV20M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}